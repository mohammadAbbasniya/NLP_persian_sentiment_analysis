{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2275ecf4",
   "metadata": {},
   "source": [
    "## [phase 2] Employe the proposed method on tests\n",
    "According to phase1, **TF-IDF** with **SVM(rbf)** scored the best result among all 18 models. Here we just use this model on test data.\n",
    "\n",
    "*Note* that you may need some variables or functions from phase 1 in phase 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a87da00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b543a6aa",
   "metadata": {},
   "source": [
    "### 2-1 Read & Prepare train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1771aba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Negative' 'Negative' 'Positive' ... 'Positive' 'Negative' 'Positive']\n",
      "[0 0 2 ... 2 0 2]\n",
      "X_train : (2543,)\n",
      "y_train : (2543,)\n",
      "X_test  : (449,)\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"sentiment_data/train.csv\")\n",
    "test_data = pd.read_csv(\"sentiment_data/test.csv\")\n",
    "\n",
    "X_train = np.array(train_data.iloc[:,0])\n",
    "y_train = np.array(train_data.iloc[:,1])\n",
    "X_test = np.array(test_data.iloc[:,0])\n",
    "\n",
    "print(y_train)\n",
    "LE2 = LabelEncoder()\n",
    "y_train = LE2.fit_transform(y_train)\n",
    "print(y_train)\n",
    "\n",
    "print(f'X_train : {X_train.shape}')\n",
    "print(f'y_train : {y_train.shape}')\n",
    "print(f'X_test  : {X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8560bf",
   "metadata": {},
   "source": [
    "### 2-2 Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d20867cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "\n",
    "vfunc = np.vectorize(lambda s: emoji_pattern.sub(r'', s))\n",
    "X_test = vfunc(X_test)\n",
    "X_train = vfunc(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97aae0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nlp_files/stop_words-fa.txt', mode='r', encoding='utf-8') as stop_words_file:\n",
    "    stop_words = stop_words_file.read().split('\\n')\n",
    "    \n",
    "with open('nlp_files/stop_puncs-fa.txt', mode='r', encoding='utf-8') as stop_puncs_file:\n",
    "    stop_puncs = stop_puncs_file.read().split('\\n') \n",
    "\n",
    "with open('nlp_files/stop_chars-fa.txt', mode='r', encoding='utf-8') as stop_chars_file:\n",
    "    stop_chars = stop_chars_file.read().split('\\n') \n",
    "\n",
    "def remove_stops(string):\n",
    "    for char in stop_chars:\n",
    "        string = string.replace(char, '') # remove stop-chars\n",
    "        \n",
    "    for punc in stop_puncs:\n",
    "        string = string.replace(punc, ' ') # replace stop-punctuations with space\n",
    "        \n",
    "    words = [word.strip() for word in string.split(' ')] # split string to trimed words \n",
    "    words = list(filter(lambda word: len(word) > 0, words)) # remove empty words\n",
    "    words = list(filter(lambda word: word not in stop_words, words)) # remove stop-words\n",
    "    \n",
    "    string = ' '.join(words)\n",
    "    return string\n",
    "\n",
    "vfunc = np.vectorize(lambda s: remove_stops(s))\n",
    "X_test = vfunc(X_test)\n",
    "X_train = vfunc(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072b5186",
   "metadata": {},
   "source": [
    "### 2-3 Vectorization with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a995decd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_vec : (2543, 7319)\n",
      "X_test_vec  : (449, 7319)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(X_train)\n",
    "\n",
    "X_train_vec = vectorizer.transform(X_train).toarray()\n",
    "X_test_vec = vectorizer.transform(X_test).toarray()\n",
    "\n",
    "print(f'X_train_vec : {X_train_vec.shape}')\n",
    "print(f'X_test_vec  : {X_test_vec.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc8838f",
   "metadata": {},
   "source": [
    "### 2-4 Classification with SVM(rbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca9ba2c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf_svm = SVC(kernel='rbf')\n",
    "clf_svm.fit(X_train_vec, y_train)\n",
    "y_pred = np.array(clf_svm.predict(X_test_vec))\n",
    "\n",
    "y_pred_categorized = np.array(LE2.inverse_transform(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35334b1e",
   "metadata": {},
   "source": [
    "### 2-5 Store predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12d1d668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>مکانی زیبا و دیدنی با چشم اندازی زیبا برای علا...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>روز جمعه داخل نشان زده بود باز است ولی بسته بود</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>سلام\\nمتاسفانه با اپراتور متقلبی در این پمپ بن...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>محوطه بزرگ و فضای سبز خوبی دارد</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>مزه خوبی نداره شیرینی وکیک هاش</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>مکانی بسیار زیبا و دلنشین که علاوه بر کاخ موزه...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>حیف  غذا یک خاطر ساز است واشپز کسی که باعشق خا...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>افتضاح و گرون تر از بقیه</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>مسجد کرمانی یکی از مسجدهای قدیمی شهر تربت جام ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>قبلاً وسایلش بهتر بود</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>449 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               comment sentiment\n",
       "0    مکانی زیبا و دیدنی با چشم اندازی زیبا برای علا...  Positive\n",
       "1      روز جمعه داخل نشان زده بود باز است ولی بسته بود  Negative\n",
       "2    سلام\\nمتاسفانه با اپراتور متقلبی در این پمپ بن...  Negative\n",
       "3                      محوطه بزرگ و فضای سبز خوبی دارد  Positive\n",
       "4                       مزه خوبی نداره شیرینی وکیک هاش  Negative\n",
       "..                                                 ...       ...\n",
       "444  مکانی بسیار زیبا و دلنشین که علاوه بر کاخ موزه...  Positive\n",
       "445  حیف  غذا یک خاطر ساز است واشپز کسی که باعشق خا...  Negative\n",
       "446                           افتضاح و گرون تر از بقیه  Negative\n",
       "447  مسجد کرمانی یکی از مسجدهای قدیمی شهر تربت جام ...   Neutral\n",
       "448                              قبلاً وسایلش بهتر بود  Negative\n",
       "\n",
       "[449 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file  = 'sentiment_data/test-filled.csv'\n",
    "if os.path.isfile(file):\n",
    "    os.remove(file)\n",
    "    \n",
    "test_data['sentiment'] = y_pred_categorized\n",
    "\n",
    "test_data.to_csv(file, index=False, mode='x')\n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e071abdf",
   "metadata": {},
   "source": [
    "### 2-6 individual prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1c35efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n",
      "Negative\n"
     ]
    }
   ],
   "source": [
    "def predict(comment: str):\n",
    "    comment = emoji_pattern.sub(r'', comment)\n",
    "    comment = remove_stops(comment)\n",
    "    \n",
    "    vec = vectorizer.transform([comment]).toarray()\n",
    "    \n",
    "    res = clf_svm.predict(vec)\n",
    "    category = LE2.inverse_transform(res)[0]\n",
    "    return category\n",
    "\n",
    "print(predict('بسیار جای خوبی بود من راضی بودم همه چیز عالی'))\n",
    "print(predict('واقعا بد بود خیلی کثیف و نا مرتب'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
